# LLM Provider Configuration
# OpenAI (default)
OPENAI_API_KEY="YOUR_OPENAI_API_KEY"

# Anthropic Claude
ANTHROPIC_API_KEY="YOUR_ANTHROPIC_API_KEY"

# Google Gemini
GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY"

# OpenRouter (multi-provider aggregator)
OPENROUTER_API_KEY="YOUR_OPENROUTER_API_KEY"

# Local LLM Configuration
# Ollama (default: http://localhost:11434)
OLLAMA_BASE_URL="http://localhost:11434"

# LM Studio (default: http://localhost:1234/v1)
LMSTUDIO_BASE_URL="http://localhost:1234/v1"

# Default provider (openai|anthropic|gemini|openrouter|ollama|lmstudio)
DEFAULT_LLM_PROVIDER="openai"

# CLI Tools Configuration
# Claude CLI path (set to actual path where claude CLI is installed)
CLAUDE_CLI_PATH="claude"

# Gemini CLI path (set to actual path where gemini CLI is installed)  
GEMINI_CLI_PATH="gemini"

# Enable CLI-first mode (prefers CLI tools over API calls)
CLI_FIRST_MODE="true"

# Background task timeout (in seconds)
BACKGROUND_TASK_TIMEOUT="300"

LANGCHAIN_CALLBACKS_BACKGROUND=false

# Required for agent example
# SERPAPI_API_KEY="YOUR_API_KEY"

# Required for retrieval examples
# SUPABASE_PRIVATE_KEY="YOUR_SUPABASE_PRIVATE_KEY"
# SUPABASE_URL="YOUR_SUPABASE_URL"

# Optional: For Tracing with LangSmith
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=YOUR_API_KEY
# LANGCHAIN_PROJECT=nextjs-starter

# Turn on demo mode
# NEXT_PUBLIC_DEMO="true"